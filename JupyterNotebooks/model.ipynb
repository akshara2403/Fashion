{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the dataset class\n",
    "\n",
    "# class FashionDataset(Dataset):\n",
    "#     def __init__(self, csv_file, root_dir, transform=None):\n",
    "#         try:\n",
    "#             self.data = pd.read_csv(csv_file)\n",
    "#         except pd.errors.ParserError as e:\n",
    "#             print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "    #     self.root_dir = root_dir\n",
    "    #     self.transform = transform\n",
    "\n",
    "    #     # Add encoding for categorical variables (assuming masterCategory and baseColour are categorical)\n",
    "    #     self.master_category_encoding = {category: idx for idx, category in enumerate(self.data['masterCategory'].unique())}\n",
    "    #     self.color_encoding = {color: idx for idx, color in enumerate(self.data['baseColour'].unique())}\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return len(self.data)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     img_name = str(self.data.iloc[idx, 0]) + '.jpg'\n",
    "    #     img_path = os.path.join(self.root_dir, img_name)\n",
    "    #     image = read_image(img_path)\n",
    "\n",
    "    #     # Encode categorical variables\n",
    "    #     master_category = torch.tensor(self.master_category_encoding[self.data.iloc[idx, 2]], dtype=torch.long)\n",
    "    #     color_label = torch.tensor(self.color_encoding[self.data.iloc[idx, 5]], dtype=torch.long)\n",
    "\n",
    "    #     if self.transform:\n",
    "    #         image = self.transform(image)\n",
    "\n",
    "    #     return {'image': image, 'master_category': master_category, 'color_label': color_label}\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "\n",
    "# Define the dataset class\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file,on_bad_lines='skip')\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Add encoding for categorical variables (assuming masterCategory and baseColour are categorical)\n",
    "        self.master_category_encoding = {category: idx for idx, category in enumerate(self.data['masterCategory'].unique())}\n",
    "        self.color_encoding = {color: idx for idx, color in enumerate(self.data['baseColour'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.data.iloc[idx, 0]) + '.jpg'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        # Encode categorical variables\n",
    "        master_category = torch.tensor(self.master_category_encoding[self.data.iloc[idx, 2]], dtype=torch.long)\n",
    "        color_label = torch.tensor(self.color_encoding[self.data.iloc[idx, 5]], dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {'image': image, 'master_category': master_category, 'color_label': color_label}\n",
    "\n",
    "# Rest of your code...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionModel(nn.Module):\n",
    "    def __init__(self, num_master_categories, num_colors):\n",
    "        super(FashionModel, self).__init__()\n",
    "        self.conv_final = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Example input size (batch_size, channels, height, width)\n",
    "        sample_image = torch.randn((3, num_channels, 512, 640))\n",
    "        conv_out = self.conv_final(sample_image)\n",
    "        flattened_size = self.flatten(conv_out).size(1)\n",
    "\n",
    "        self.fc_master_category = nn.Linear(flattened_size, num_master_categories)\n",
    "        self.fc_color = nn.Linear(flattened_size, num_colors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_final(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        master_category_output = self.fc_master_category(x)\n",
    "        color_output = self.fc_color(x)\n",
    "        return master_category_output, color_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset and dataloaders\n",
    "from torchvision import transforms\n",
    "csv_file = '/Users/akshararamprasad/Documents/Fashion/styles.csv'\n",
    "root_dir = '/Users/akshararamprasad/Documents/Fashion/imagesdata'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((512,640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = FashionDataset(csv_file, root_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "# Instantiate the model\n",
    "num_channels = 3\n",
    "num_master_categories = len(dataset.data['masterCategory'].unique())\n",
    "num_colors = len(dataset.data['baseColour'].unique())\n",
    "model = FashionModel(num_master_categories, num_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Master Category: tensor([5])\n",
      "Predicted Color: tensor([44])\n"
     ]
    }
   ],
   "source": [
    "# # Inference example\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     sample = next(iter(test_loader))\n",
    "#     images = sample['image']\n",
    "#     master_category_labels = sample['master_category']\n",
    "#     color_labels = sample['color_label']\n",
    "\n",
    "#     master_category_output, color_output = model(images)\n",
    "#     predicted_master_category = torch.argmax(master_category_output, dim=1)\n",
    "#     predicted_color = torch.argmax(color_output, dim=1)\n",
    "\n",
    "#     print(\"Predicted Master Category:\", predicted_master_category)\n",
    "#     print(\"Predicted Color:\", predicted_color)\n",
    "# Inference example\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample = next(iter(test_loader))\n",
    "    images = sample['image']\n",
    "    master_category_labels = sample['master_category']\n",
    "    color_labels = sample['color_label']\n",
    "\n",
    "    # Ensure images have 3 channels (adjust as needed)\n",
    "    if images.size(1) == 1:\n",
    "        images = torch.cat([images] * 3, dim=1)\n",
    "\n",
    "    master_category_output, color_output = model(images)\n",
    "    predicted_master_category = torch.argmax(master_category_output, dim=1)\n",
    "    predicted_color = torch.argmax(color_output, dim=1)\n",
    "\n",
    "    print(\"Predicted Master Category:\", predicted_master_category)\n",
    "    print(\"Predicted Color:\", predicted_color)\n",
    "\n",
    "# Evaluation\n",
    "# ... (previous code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Master Category: Sporting Goods\n",
      "Predicted Color: Mushroom Brown\n"
     ]
    }
   ],
   "source": [
    "master_category_encoding = {\n",
    "    0: 'Apparel',\n",
    "    1: 'Accessories',\n",
    "    2: 'Footwear',\n",
    "    3: 'Personal Care',\n",
    "    4: 'Free Items',\n",
    "    5: 'Sporting Goods',\n",
    "    6: 'Home'\n",
    "}\n",
    "\n",
    "# Dictionary for baseColour\n",
    "color_encoding = {\n",
    "    0: 'Navy Blue',\n",
    "    1: 'Blue',\n",
    "    2: 'Silver',\n",
    "    3: 'Black',\n",
    "    4: 'Grey',\n",
    "    5: 'Green',\n",
    "    6: 'Purple',\n",
    "    7: 'White',\n",
    "    8: 'Beige',\n",
    "    9: 'Brown',\n",
    "    10: 'Bronze',\n",
    "    11: 'Teal',\n",
    "    12: 'Copper',\n",
    "    13: 'Pink',\n",
    "    14: 'Off White',\n",
    "    15: 'Maroon',\n",
    "    16: 'Red',\n",
    "    17: 'Khaki',\n",
    "    18: 'Orange',\n",
    "    19: 'Yellow',\n",
    "    20: 'Charcoal',\n",
    "    21: 'Gold',\n",
    "    22: 'Steel',\n",
    "    23: 'Tan',\n",
    "    24: 'Multi',\n",
    "    25: 'Magenta',\n",
    "    26: 'Lavender',\n",
    "    27: 'Sea Green',\n",
    "    28: 'Cream',\n",
    "    29: 'Peach',\n",
    "    30: 'Olive',\n",
    "    31: 'Skin',\n",
    "    32: 'Burgundy',\n",
    "    33: 'Coffee Brown',\n",
    "    34: 'Grey Melange',\n",
    "    35: 'Rust',\n",
    "    36: 'Rose',\n",
    "    37: 'Lime Green',\n",
    "    38: 'Mauve',\n",
    "    39: 'Turquoise Blue',\n",
    "    40: 'Metallic',\n",
    "    41: 'Mustard',\n",
    "    42: 'Taupe',\n",
    "    43: 'Nude',\n",
    "    44: 'Mushroom Brown',\n",
    "    45: 'Fluorescent Green'\n",
    "}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample = next(iter(test_loader))\n",
    "    images = sample['image']\n",
    "\n",
    "    master_category_output, color_output = model(images)\n",
    "    predicted_master_category_index = torch.argmax(master_category_output, dim=1).item()\n",
    "    predicted_color_index = torch.argmax(color_output, dim=1).item()\n",
    "\n",
    "    # Get predicted labels from encoding dictionaries\n",
    "    predicted_master_category_label = master_category_encoding[predicted_master_category_index]\n",
    "    predicted_color_label = color_encoding[predicted_color_index]\n",
    "\n",
    "    print(\"Predicted Master Category:\", predicted_master_category_label)\n",
    "    print(\"Predicted Color:\", predicted_color_label)\n",
    "# Save the color model\n",
    "torch.save(model.fc_color.state_dict(), 'color_model.pth')\n",
    "\n",
    "# Save the category model\n",
    "torch.save(model.fc_master_category.state_dict(), 'category_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
